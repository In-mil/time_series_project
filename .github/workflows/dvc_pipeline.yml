name: DVC Training & Evaluation Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'

      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Cache DVC
        uses: actions/cache@v4
        with:
          path: .dvc/cache
          key: ${{ runner.os }}-dvc-${{ hashFiles('**/*.dvc', 'dvc.lock') }}
          restore-keys: |
            ${{ runner.os }}-dvc-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install "dvc[gs]" tensorflow==2.15.0 mlflow scikit-learn pandas numpy matplotlib seaborn google-cloud-storage

      - name: Configure Google Cloud & DVC
        env:
          GCP_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
        run: |
          echo "$GCP_KEY" > gcp_creds.json
          gcloud auth activate-service-account --key-file=gcp_creds.json
          dvc remote modify gcsremote credentialpath gcp_creds.json
          dvc remote default gcsremote
          mkdir -p .dvc/cache
          dvc config cache.dir .dvc/cache

      - name: Pull dataset & models from GCS
        run: |
          echo "Pulling dataset from remote storage..."
          dvc pull data/final_data/20251115_dataset_crp.csv.dvc -r gcsremote --force -v || (echo "Dataset pull failed"; exit 1)
          echo "Pulling all model artifacts from remote storage..."
          dvc pull -r gcsremote --force -v || echo "Some artifacts not yet in remote, will be generated"
          echo "Verifying dataset file exists..."
          ls -lh data/final_data/ || true
          if [ ! -f "data/final_data/20251115_dataset_crp.csv" ]; then
            echo "Dataset missing after pull – aborting!"
            exit 1
          fi
          echo "Dataset successfully pulled and verified"

      - name: Check pipeline status
        run: |
          echo "Checking which stages need to be run..."
          dvc status

      - name: Run pipeline (parallel training)
        env:
          MLFLOW_TRACKING_URI: file:./mlruns
        run: |
          echo "==================================="
          echo "Starting parallel model training..."
          echo "==================================="

          # Train base models in parallel (they're independent)
          echo "[1/3] Training 4 base models in parallel..."
          dvc repro train_ann -v &
          PID_ANN=$!
          dvc repro train_gru -v &
          PID_GRU=$!
          dvc repro train_lstm -v &
          PID_LSTM=$!
          dvc repro train_transformer -v &
          PID_TRANSFORMER=$!

          # Wait for all parallel processes and check for failures
          echo "Waiting for parallel training to complete..."
          FAILED=0
          wait $PID_ANN || { echo "❌ ANN training failed"; FAILED=1; }
          wait $PID_GRU || { echo "❌ GRU training failed"; FAILED=1; }
          wait $PID_LSTM || { echo "❌ LSTM training failed"; FAILED=1; }
          wait $PID_TRANSFORMER || { echo "❌ Transformer training failed"; FAILED=1; }

          if [ $FAILED -eq 1 ]; then
            echo "One or more models failed to train"
            exit 1
          fi

          echo "✅ All base models trained successfully"

          # Train ensemble model (depends on all base models)
          echo "[2/3] Training ensemble model..."
          dvc repro train_ensemble -v || { echo "❌ Ensemble training failed"; exit 1; }
          echo "✅ Ensemble model trained"

          # Evaluate all models
          echo "[3/3] Evaluating models..."
          dvc repro evaluate_models -v || { echo "❌ Evaluation failed"; exit 1; }
          echo "✅ Evaluation complete"

          echo "==================================="
          echo "Pipeline completed successfully!"
          echo "==================================="

      - name: Push updated artifacts and metrics to GCS
        run: |
          echo "Pushing DVC artifacts..."
          dvc commit evaluate_models || true
          dvc push -r gcsremote -v

      - name: Upload evaluation report as artifact
        uses: actions/upload-artifact@v4
        with:
          name: model-evaluation-report
          path: reports/metrics.json
