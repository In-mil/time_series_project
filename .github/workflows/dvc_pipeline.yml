name: DVC Training & Evaluation Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'

      - name: Cache Python virtual environment
        uses: actions/cache@v4
        id: venv-cache
        with:
          path: |
            ~/.local/lib/python3.11/site-packages
            ~/.local/bin
          key: ${{ runner.os }}-venv-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-venv-

      - name: Install dependencies
        if: steps.venv-cache.outputs.cache-hit != 'true'
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Configure Google Cloud & DVC
        env:
          GCP_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
        run: |
          set -euo pipefail

          echo "$GCP_KEY" > gcp_creds.json

          # Activate service account and verify
          if ! gcloud auth activate-service-account --key-file=gcp_creds.json; then
            echo "❌ Failed to authenticate with Google Cloud"
            exit 1
          fi

          echo "✅ GCloud authenticated successfully"

          # Configure DVC (no local cache to avoid state inconsistencies)
          dvc remote modify gcsremote credentialpath gcp_creds.json
          dvc remote default gcsremote

      - name: Pull dataset & models from GCS
        run: |
          set -euo pipefail

          echo "Pulling dataset from remote storage..."

          # Two-step process: fetch (downloads to cache) + checkout (copies to working dir)
          # This is more reliable than 'dvc pull' which skips when it thinks things are up-to-date

          echo "Step 1: Fetching to cache..."
          dvc fetch data/final_data/20251115_dataset_crp.csv.dvc -r gcsremote -v

          echo "Step 2: Checking out to working directory..."
          dvc checkout data/final_data/20251115_dataset_crp.csv.dvc --force -v

          # Verify dataset exists
          if [ ! -f "data/final_data/20251115_dataset_crp.csv" ]; then
            echo "❌ Dataset missing after fetch+checkout!"
            echo "Cache status:"
            find .dvc/cache -type f -ls 2>/dev/null | head -5 || echo "No cache files"
            echo "Working directory status:"
            ls -lh data/final_data/
            exit 1
          fi

          echo "✅ Dataset verified: $(du -h data/final_data/20251115_dataset_crp.csv | cut -f1)"

          # Fetch model artifacts in parallel (if available)
          echo "Fetching model artifacts in parallel..."

          # Use fetch + checkout strategy for reliability
          (dvc fetch models/model_ann.keras.dvc -r gcsremote 2>/dev/null && dvc checkout models/model_ann.keras.dvc --force 2>/dev/null) || echo "⚠ ANN model not in remote" &
          (dvc fetch models/model_gru.keras.dvc -r gcsremote 2>/dev/null && dvc checkout models/model_gru.keras.dvc --force 2>/dev/null) || echo "⚠ GRU model not in remote" &
          (dvc fetch models/model_lstm.keras.dvc -r gcsremote 2>/dev/null && dvc checkout models/model_lstm.keras.dvc --force 2>/dev/null) || echo "⚠ LSTM model not in remote" &
          (dvc fetch models/model_transformer.keras.dvc -r gcsremote 2>/dev/null && dvc checkout models/model_transformer.keras.dvc --force 2>/dev/null) || echo "⚠ Transformer model not in remote" &
          (dvc fetch models/model_ensemble.json.dvc -r gcsremote 2>/dev/null && dvc checkout models/model_ensemble.json.dvc --force 2>/dev/null) || echo "⚠ Ensemble model not in remote" &
          (dvc fetch artifacts/ensemble.dvc -r gcsremote 2>/dev/null && dvc checkout artifacts/ensemble.dvc --force 2>/dev/null) || echo "⚠ Ensemble artifacts not in remote" &
          (dvc fetch reports/metrics.json.dvc -r gcsremote 2>/dev/null && dvc checkout reports/metrics.json.dvc --force 2>/dev/null) || echo "⚠ Metrics not in remote" &

          # Wait for all parallel operations
          wait

          echo "✅ All available artifacts fetched and checked out"

      - name: Check pipeline status
        id: dvc-status
        run: |
          set -eo pipefail  # Note: no 'u' here because we check if vars are set

          echo "Checking which stages need to be run..."

          # Run dvc status and capture both output and exit code
          if STATUS_OUTPUT=$(dvc status 2>&1); then
            echo "$STATUS_OUTPUT"

            # Check if pipeline is up to date
            if echo "$STATUS_OUTPUT" | grep -q "Data and pipelines are up to date"; then
              echo "pipeline_changed=false" >> $GITHUB_OUTPUT
              echo "✅ Pipeline is up to date - no training needed"
            else
              echo "pipeline_changed=true" >> $GITHUB_OUTPUT
              echo "⚠️  Pipeline changes detected - training will run"
              echo "Changes:"
              echo "$STATUS_OUTPUT"
            fi
          else
            # DVC status failed - assume we need to run pipeline
            echo "⚠️  DVC status check failed, assuming changes exist"
            echo "$STATUS_OUTPUT"
            echo "pipeline_changed=true" >> $GITHUB_OUTPUT
          fi

      - name: Run pipeline (smart parallel training with DVC)
        if: steps.dvc-status.outputs.pipeline_changed == 'true'
        env:
          MLFLOW_TRACKING_URI: file:./mlruns
        run: |
          set -euo pipefail

          echo "==================================="
          echo "Starting DVC pipeline..."
          echo "==================================="

          # Use DVC repro with --jobs 4 for parallel execution
          # DVC will intelligently:
          # - Only run stages with changed dependencies (skip unchanged stages)
          # - Run up to 4 stages in parallel (train_ann, train_gru, train_lstm, train_transformer)
          # - Automatically handle dependencies (train_ensemble after base models, evaluate_models after ensemble)

          echo "Running pipeline with intelligent dependency tracking and parallel execution..."
          dvc repro evaluate_models --jobs 4 -v

          echo "==================================="
          echo "Pipeline completed successfully!"
          echo "==================================="

      - name: Push updated artifacts and metrics to GCS
        if: steps.dvc-status.outputs.pipeline_changed == 'true'
        run: |
          set -euo pipefail

          echo "Pushing DVC artifacts..."
          dvc commit evaluate_models || true
          dvc push -r gcsremote -v

      - name: Skip message
        if: steps.dvc-status.outputs.pipeline_changed == 'false'
        run: |
          echo "⏭️  No changes detected - skipped training, evaluation, and artifact push"
          echo "Pipeline and data are up to date!"

      - name: Upload evaluation report as artifact
        if: steps.dvc-status.outputs.pipeline_changed == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: model-evaluation-report
          path: reports/metrics.json
