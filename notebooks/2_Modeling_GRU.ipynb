{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4hk8e1dd9k",
   "metadata": {},
   "source": [
    "# GRU Model for Crypto Price Prediction\n",
    "\n",
    "**Target**: Predicting whether the crypto price will be higher in 5 days than it is today  \n",
    "**Method**: Gated Recurrent Unit (GRU) - Recurrent Neural Network with TensorFlow/Keras\n",
    "\n",
    "## What is GRU?\n",
    "- **Recurrent architecture**: Processes sequences of data (20-day windows)\n",
    "- **2 gates**: Update gate and Reset gate for memory control\n",
    "- **Temporal awareness**: Learns patterns across time (e.g., \"prices usually rise 3 days after a drop\")\n",
    "- **Lightweight RNN**: Simpler than LSTM (~35K parameters), faster training\n",
    "- **Built-in memory**: No need for manual lag features, learns temporal dependencies automatically\n",
    "- **Data shape**: 3D input (samples, timesteps, features) = (139,766 sequences, 20 days, 68 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standart libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "from pathlib import Path \n",
    "\n",
    "# project specific libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "# random seeds for reproducibility e.g. initialisation of weights in NN\n",
    "SEED = 101 #usually 42 but for uniformity 101\n",
    "tf.random.set_seed(SEED) #weight initialization, dropout masks, batch shuffling\n",
    "np.random.seed(SEED) #array operations, train_test_split, data transformations\n",
    "random.seed(SEED) #random(), shuffle(), choice()\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88add955",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gru = pd.read_csv(\"/Users/ina/Documents/spicedAcademy/time_series_project/data/final_data/20251115_dataset_crp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49bf025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation-Test Split (70%-15%-15% temporal split)\n",
    "split_date_train = \"2024-07-01\"  # Training until this date\n",
    "split_date_val = \"2024-10-01\"    # Validation from here\n",
    "split_date_test = \"2025-01-01\"   # Testing from here\n",
    "\n",
    "#parameter\n",
    "x_cols_to_drop = ['ticker', 'date', 'future_5_close_higher_than_today', 'future_10_close_higher_than_today',\n",
    "\"future_5_close_lower_than_today\", \"future_10_close_lower_than_today\", \"higher_close_today_vs_future_5_close\", \n",
    "\"higher_close_today_vs_future_10_close\", \"lower_close_today_vs_future_5_close\", \"lower_close_today_vs_future_10_close\"]\n",
    "\n",
    "df_train = df_gru[df_gru['date'] < split_date_train].copy()\n",
    "df_val = df_gru[(df_gru['date'] >= split_date_train) & (df_gru['date'] < split_date_val)].copy()\n",
    "df_test = df_gru[df_gru['date'] >= split_date_test].copy()\n",
    "\n",
    "print(f\"\\nTraining set: {len(df_train)} samples\")\n",
    "print(f\"Validation set: {len(df_val)} samples\")\n",
    "print(f\"Test set: {len(df_test)} samples\")\n",
    "print(f\"Train up to date: {df_train['date'].max()}\")\n",
    "print(f\"Validation from date: {df_val['date'].min()} to {df_val['date'].max()}\")\n",
    "print(f\"Test from date: {df_test['date'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df036bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and targets - KEEP 'ticker' and 'date' for sequence creation\n",
    "# For GRU, we need these columns to:\n",
    "# - Sort data chronologically (date)\n",
    "# - Create sequences per cryptocurrency (ticker)\n",
    "\n",
    "# Features: exclude targets but KEEP 'ticker' and 'date' temporarily\n",
    "feature_cols = [col for col in df_train.columns \n",
    "                if col not in ['future_5_close_higher_than_today', 'future_10_close_higher_than_today',\n",
    "                              'future_5_close_lower_than_today', 'future_10_close_lower_than_today',\n",
    "                              'higher_close_today_vs_future_5_close', 'higher_close_today_vs_future_10_close',\n",
    "                              'lower_close_today_vs_future_5_close', 'lower_close_today_vs_future_10_close']]\n",
    "\n",
    "X_train = df_train[feature_cols].copy()\n",
    "y_train = df_train[\"future_5_close_higher_than_today\"].values\n",
    "\n",
    "X_val = df_val[feature_cols].copy()\n",
    "y_val = df_val[\"future_5_close_higher_than_today\"].values\n",
    "\n",
    "X_test = df_test[feature_cols].copy()\n",
    "y_test = df_test[\"future_5_close_higher_than_today\"].values\n",
    "\n",
    "# Scaling - GLOBAL scaling (all tickers together, simpler than per-ticker)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Prepare data for scaling (exclude ticker and date from scaling)\n",
    "cols_to_scale = [col for col in X_train.columns if col not in ['ticker', 'date']]\n",
    "\n",
    "# Fit on training data ONLY (avoid leakage)\n",
    "X_train_scaled_vals = scaler_X.fit_transform(X_train[cols_to_scale])\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Transform validation and test data\n",
    "X_val_scaled_vals = scaler_X.transform(X_val[cols_to_scale])\n",
    "y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1)).ravel()\n",
    "\n",
    "X_test_scaled_vals = scaler_X.transform(X_test[cols_to_scale])\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "print(f\"   Features shape: {X_train_scaled_vals.shape}\")\n",
    "print(f\"   Target shape: {y_train_scaled.shape}\")\n",
    "print(f\"   Note: 'ticker' and 'date' kept for sequence creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5elucvps0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for GRU (convert 2D to 3D data)\n",
    "# GRU needs: (samples, timesteps, features) instead of (samples, features)\n",
    "\n",
    "def create_sequences(X_data, y_data, df, look_back=20):\n",
    "    \"\"\"Create sliding window sequences for each crypto separately\n",
    "    \n",
    "    Returns sequences AND original indices for alignment\n",
    "    \"\"\"\n",
    "    \n",
    "    X_sequences = []\n",
    "    y_sequences = []\n",
    "    original_indices = []  # Track which original row each sequence comes from\n",
    "    \n",
    "    # Process each cryptocurrency separately\n",
    "    for ticker in df['ticker'].unique():\n",
    "        # Get data for this crypto only\n",
    "        mask = df['ticker'] == ticker\n",
    "        ticker_indices = df[mask].index.values  # Original dataframe indices\n",
    "        crypto_X = X_data[mask]\n",
    "        crypto_y = y_data[mask]\n",
    "        crypto_dates = df.loc[mask, 'date'].values\n",
    "        \n",
    "        # Sort by date (important for time series!)\n",
    "        order = np.argsort(crypto_dates)\n",
    "        crypto_X = crypto_X[order]\n",
    "        crypto_y = crypto_y[order]\n",
    "        ticker_indices = ticker_indices[order]\n",
    "        \n",
    "        # Create sliding windows\n",
    "        for i in range(len(crypto_X) - look_back):\n",
    "            X_sequences.append(crypto_X[i:i+look_back])  # Past days\n",
    "            y_sequences.append(crypto_y[i + look_back])  # Future target\n",
    "            original_indices.append(ticker_indices[i + look_back])  # Track original index\n",
    "    \n",
    "    return np.array(X_sequences), np.array(y_sequences), np.array(original_indices)\n",
    "\n",
    "\n",
    "# Settings\n",
    "look_back = 20  # Use past 20 days to predict\n",
    "\n",
    "# Create sequences for all splits (now with indices)\n",
    "print(\"Creating sequences...\")\n",
    "X_train_seq, y_train_seq, train_indices = create_sequences(X_train_scaled_vals, y_train_scaled, X_train, look_back)\n",
    "X_val_seq, y_val_seq, val_indices = create_sequences(X_val_scaled_vals, y_val_scaled, X_val, look_back)\n",
    "X_test_seq, y_test_seq, test_indices = create_sequences(X_test_scaled_vals, y_test_scaled, X_test, look_back)\n",
    "\n",
    "# Get dimensions for model\n",
    "n_features = X_train_seq.shape[2]\n",
    "\n",
    "print(f\"\\nShape: {X_train_seq.shape}\")\n",
    "print(f\"   {X_train_seq.shape[0]} sequences\")\n",
    "print(f\"   {look_back} days look-back\")\n",
    "print(f\"   {n_features} features\")\n",
    "print(f\"   Indices tracked for alignment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL ARCHITECTURE - GRU for Time Series Prediction\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "\n",
    "# Hyperparameters\n",
    "gru_units = 64\n",
    "gru_dropout = 0.3\n",
    "use_second_gru = True\n",
    "dense_units = 32\n",
    "dense_dropout = 0.2\n",
    "learning_rate = 0.0001\n",
    "L2_regularization = 0.0001\n",
    "\n",
    "# Build model based on configuration\n",
    "if use_second_gru:\n",
    "    model_gru = Sequential([\n",
    "        Input(shape=(look_back, n_features)),\n",
    "        \n",
    "        # First GRU layer\n",
    "        GRU(gru_units, \n",
    "            return_sequences=True,  # MUST be True for stacked GRU\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(L2_regularization),\n",
    "            name='gru_layer_1'),\n",
    "        Dropout(gru_dropout, name='dropout_1'),\n",
    "        \n",
    "        # Second GRU layer\n",
    "        GRU(gru_units // 2, \n",
    "            return_sequences=False,  # False for last GRU layer\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(L2_regularization),\n",
    "            name='gru_layer_2'),\n",
    "        Dropout(gru_dropout, name='dropout_2'),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(1, activation='linear', name='output')\n",
    "    ])\n",
    "else:\n",
    "    model_gru = Sequential([\n",
    "        Input(shape=(look_back, n_features)),\n",
    "        \n",
    "        # Single GRU layer\n",
    "        GRU(gru_units, \n",
    "            return_sequences=False,  # Only output last timestep\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(L2_regularization),\n",
    "            name='gru_layer'),\n",
    "        Dropout(gru_dropout, name='dropout'),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(1, activation='linear', name='output')\n",
    "    ])\n",
    "\n",
    "# Compile model\n",
    "model_gru.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss='mae',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "print(\"GRU Model Architecture:\")\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN GRU MODEL\n",
    "\n",
    "# Training parameters\n",
    "epochs = 100\n",
    "batch_size = 128  # Smaller batch size for GRU (time series, more memory intensive)\n",
    "patience = 10\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=patience,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model with sequences\n",
    "history = model_gru.fit(\n",
    "    X_train_seq, y_train_seq,  # 3D sequences\n",
    "    validation_data=(X_val_seq, y_val_seq),  # Use validation se\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xz1k15xom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "mae_train = history.history['mae'][-1]\n",
    "mse_train = history.history['mse'][-1]\n",
    "print(\"Train Set Performance:\")\n",
    "print(f\"   MAE:  {mae_train:.4f}\")\n",
    "print(f\"   MSE:  {mse_train:.4f}\")\n",
    "\n",
    "val_mae = history.history['val_mae'][-1]\n",
    "val_mse = history.history['val_mse'][-1]\n",
    "print(\"\\nValidation Set Performance:\")\n",
    "print(f\"   MAE:  {val_mae:.4f}\")\n",
    "print(f\"   MSE:  {val_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ls2forwrp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history - GRU\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14,4))\n",
    "\n",
    "# MAE\n",
    "axes[0].plot(history.history['mae'], label='training mae', linewidth=2)\n",
    "axes[0].plot(history.history['val_mae'], label='validation mae', linewidth=2)\n",
    "axes[0].set_xlabel('epoch')\n",
    "axes[0].set_ylabel('mae')\n",
    "axes[0].set_title('GRU: Mean Absolute Error')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MSE\n",
    "axes[1].plot(history.history['mse'], label='training mse', linewidth=2)\n",
    "axes[1].plot(history.history['val_mse'], label='validation mse', linewidth=2)\n",
    "axes[1].set_xlabel('epoch')\n",
    "axes[1].set_ylabel('mse')\n",
    "axes[1].set_title('GRU: Mean Squared Error')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k4szww2gtw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "y_pred_scaled = model_gru.predict(X_test_seq)\n",
    "\n",
    "# Metrics on scaled data\n",
    "mae = mean_absolute_error(y_test_seq, y_pred_scaled)\n",
    "mse = mean_squared_error(y_test_seq, y_pred_scaled)\n",
    "\n",
    "print(\"Test Set Performance (Scaled Data):\")\n",
    "print(f\"   MAE:  {mae:.4f}\")\n",
    "print(f\"   MSE:  {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8vs7ae7tify",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INVERSE TRANSFORM - Convert predictions back to original scale\n",
    "# Option B: Align with original data using tracked indices\n",
    "\n",
    "# Inverse transform predictions\n",
    "y_pred_original = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Get actual original values using the tracked indices\n",
    "# test_indices tells us which rows from df_test each prediction corresponds to\n",
    "y_test_original = df_test.loc[test_indices, 'future_5_close_higher_than_today'].values\n",
    "\n",
    "# Calculate metrics on ORIGINAL scale\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "\n",
    "print(\"Test Set Performance (Original Scale):\")\n",
    "print(f\"   MAE:  {mae:.4f} percentage points\")\n",
    "print(f\"   MSE:  {mse:.4f}\")\n",
    "print(f\"\\nNote: {len(y_pred_original)} predictions aligned with original data using indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rbuvfzjviqs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: Predicted vs Actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_seq, y_pred_scaled, alpha=0.5, s=10)\n",
    "plt.plot([y_test_seq.min(), y_test_seq.max()], \n",
    "         [y_test_seq.min(), y_test_seq.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Values (Scaled)')\n",
    "plt.ylabel('Predicted Values (Scaled)')\n",
    "plt.title('GRU: Predicted vs Actual (Test Set)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8yg6wwyvu3q",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: Residuals Analysis - GRU\n",
    "residuals = y_test_original - y_pred_original\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Residuals histogram\n",
    "axes[0].hist(residuals, bins=50, edgecolor='black')\n",
    "axes[0].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Residual (Actual - Predicted)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('GRU: Distribution of Residuals')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals vs Predicted\n",
    "axes[1].scatter(y_pred_original, residuals, alpha=0.5, s=10)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Predicted Values')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].set_title('GRU: Residuals vs Predicted')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residual Stats:\")\n",
    "print(f\"   Mean: {residuals.mean():.4f}\")\n",
    "print(f\"   Std:  {residuals.std():.4f}\")\n",
    "print(f\"   Min:  {residuals.min():.4f}\")\n",
    "print(f\"   Max:  {residuals.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759aaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set metrics from the last epoch\n",
    "\n",
    "mae_train = history.history['mae'][-1] #last epoch\n",
    "mse_train = history.history['mse'][-1]\n",
    "print(\"Train Set Performance:\")\n",
    "print(f\"   mae:  {mae_train:.4f}\")\n",
    "print(f\"   mse:  {mse_train:.4f}\")\n",
    "\n",
    "\n",
    "# validation set metrics from the last epoch\n",
    "val_mae = history.history['val_mae'][-1]\n",
    "val_mse = history.history['val_mse'][-1]\n",
    "print(\"\\n Validation Set Performance:\")\n",
    "print(f\"   mae:  {val_mae:.4f}\")\n",
    "print(f\"   mse:  {val_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training history\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14,4))\n",
    "\n",
    "# mae\n",
    "axes[0].plot(history.history['mae'], label='training mae', linewidth=2) #Mean Absolute Error on Training Data Set\n",
    "axes[0].plot(history.history['val_mae'], label='validation mae', linewidth=2) # Mean Absolute Error on Validation Data Set\n",
    "axes[0].set_xlabel('epoch')\n",
    "axes[0].set_ylabel('mae')\n",
    "axes[0].set_title('Mean Absolute Error')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "#mse\n",
    "axes[1].plot(history.history['mse'], label='training mse', linewidth=2) #Mean Squared Error on Training Data Set\n",
    "axes[1].plot(history.history['val_mse'], label='validation mae', linewidth=2) # Mean Squared Error on Validation Data Set\n",
    "axes[1].set_xlabel('epoch')\n",
    "axes[1].set_ylabel('mse')\n",
    "axes[1].set_title('Mean Squared Error')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63989215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "y_pred_scaled = model_gru.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics on scaled data\n",
    "mae = mean_absolute_error(y_test_scaled, y_pred_scaled)\n",
    "mse = mean_squared_error(y_test_scaled, y_pred_scaled)\n",
    "\n",
    "print(\"Test Set Performance on Scaled Data:\")\n",
    "print(f\"   mae:  {mae:.4f}\")\n",
    "print(f\"   mse:  {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4cb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INVERSE TRANSFORM back to original scale\n",
    "y_pred_original = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate metrics on ORIGINAL scale\n",
    "mae = mean_absolute_error(y_test, y_pred_original)\n",
    "mse = mean_squared_error(y_test, y_pred_original)\n",
    "\n",
    "print(\"Test Set Performance on Original Scale:\")\n",
    "print(f\"   MAE:  {mae:.4f}\")\n",
    "print(f\"   MSE:  {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794955ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize final prediction - predicted vs. actual\n",
    "\n",
    "# How well fits the model?\n",
    "#  The red line = “perfect prediction”. \n",
    "#  Points close to the line = good model/prediction.\n",
    "#  Points scattered widely = bad model/prediction.\n",
    "#  All points ABOVE the line = model systematically underestimates.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_scaled, y_pred_scaled, alpha=0.5, s=10)\n",
    "plt.plot([y_test_scaled.min(), y_test_scaled.max()], [y_test_scaled.min(), y_test_scaled.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted vs Actual Values (Test Set)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize final prediction - residuals\n",
    "\n",
    "# Is the error / Are the residuals random?\n",
    "#  normal distribution around 0 = ideal model\n",
    "#  distribition shifted = bias, model underestimates?\n",
    "#  heavy tails = model struggles to handle extreme outliers\n",
    "residuals = y_test - y_pred_original.flatten() # y_test.shape ← 1D Array; y_pred.shape ← 1D Array => subtraction won't work\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(residuals, bins=50, edgecolor='black')\n",
    "plt.xlabel('Residual (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.axvline(x=0, color='r', linestyle='--', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379fa593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize final prediction - residuals vs. predicted\n",
    "\n",
    "# Is the error/ Are the residuals constant?\n",
    "#  constant variance/homoscedastic = good\n",
    "#  funnel shape/heteroscedastic = bad; errors became greater at high values\n",
    "#  non-linear pattern/curved shape = model is missing a feature?\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_pred_original, residuals, alpha=0.5, s=10)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Predicted')\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8de325",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru.save('/Users/ina/Documents/spicedAcademy/time_series_project//models/model_gru.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
