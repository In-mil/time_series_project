# Time Series Prediction Project

[![GitHub Actions](https://img.shields.io/github/actions/workflow/status/In-mil/time_series_project/dvc_pipeline.yml?branch=main&logo=github)](https://github.com/In-mil/time_series_project/actions)
[![DVC](https://img.shields.io/badge/DVC-enabled-blueviolet?logo=dvc)](https://dvc.org/)
[![MLflow](https://img.shields.io/badge/MLflow-tracking-orange?logo=mlflow)](https://mlflow.org/)
[![Docker](https://img.shields.io/badge/Docker-ready-2496ED?logo=docker)](https://www.docker.com/)
[![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15+-orange?logo=tensorflow)](https://www.tensorflow.org/)

---

## Overview

This project implements and compares several **deep learning architectures** for **financial time series forecasting**, using cryptocurrency and macroeconomic data.  
The models are trained and versioned with **DVC**, evaluated via **MLflow**, and deployed through **GitHub Actions**.

---

## Model Architectures

| Model | Type | Key Features | Typical Use Case |
|--------|------|---------------|------------------|
| **ANN (Artificial Neural Network)** | Feedforward dense layers | Simple and fast, no temporal context | Baseline for non-sequential dependencies |
| **GRU (Gated Recurrent Unit)** | Recurrent (2 gates) | Efficient and lightweight | Short-term sequence modeling |
| **LSTM (Long Short-Term Memory)** | Recurrent (3 gates) | Captures long-term dependencies | Complex time dependencies |
| **Transformer** | Attention-based | Learns relationships without recurrence | Scalable sequence processing |
| **Ensemble** | Averaged predictions | Combines model strengths | More stable, generalizable output |

---

##  Tracking & Storage

| Component | Location / Tool | Contents | Managed by |
|------------|------------------|-----------|-------------|
| **Code & Configs** | GitHub Repo (`main` branch) | Python scripts, notebooks, YAMLs | Git |
| **Datasets** | Google Cloud Storage (GCS) â†’ `gs://time-series-dvc-storage/.dvc/cache` | Versioned raw & processed CSV files | DVC |
| **Models** | DVC Remote (GCS) | Trained `.keras` model weights | DVC |
| **Evaluation Reports** | `/reports/metrics.json` | Final metrics (MAE, MSE) | Git |
| **Experiments** | MLflow (`mlflow.db`) | Logged metrics & artifacts | MLflow |
| **CI/CD** | `.github/workflows/dvc_pipeline.yml` | Automated training & evaluation | GitHub Actions |
| **Docker Image** | Google Container Registry (GCR) | Production-ready API container | Docker + GH Actions |


---

## Project Structure

```
.
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ dvc_pipeline.yml      # Main: Training pipeline
â”‚   â”œâ”€â”€ dvc-ci.yml            # Alternative CI config
â”‚   â””â”€â”€ docker-build.yml      # Docker build & push
â”œâ”€â”€ models/                    # Model training scripts
â”‚   â”œâ”€â”€ ann_model.py
â”‚   â”œâ”€â”€ gru_model.py
â”‚   â”œâ”€â”€ lstm_model.py
â”‚   â”œâ”€â”€ transformer_model.py
â”‚   â””â”€â”€ ensemble_model.py
â”œâ”€â”€ service/
â”‚   â””â”€â”€ app.py                # FastAPI prediction API
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ evaluate_models.py    # Model evaluation
â”œâ”€â”€ data/final_data/
â”‚   â””â”€â”€ *.csv.dvc             # DVC-tracked datasets
â”œâ”€â”€ Dockerfile                # Production container
â”œâ”€â”€ build_docker.sh           # Local Docker build
â”œâ”€â”€ dvc.yaml                  # DVC pipeline
â””â”€â”€ requirements.txt          # Dependencies
```

---

## CI/CD Pipeline Optimizations

The project features a highly optimized CI/CD pipeline with significant performance improvements:

### Performance Metrics
- **Initial pipeline:** ~60 minutes per run (sequential training)
- **Optimized pipeline:** ~3 minutes when unchanged, ~15 minutes with changes
- **Improvement:** 95% faster for unchanged code, 75% faster for full retraining

### Key Optimizations
1. **Dependency Caching**
   - Python packages cached based on `requirements.txt` hash
   - Reduces installation time from 3 min â†’ 30 sec

2. **DVC Artifact Caching**
   - Models and datasets cached between runs
   - Only pulls what changed
   - Reduces pull time from 2 min â†’ 10 sec

3. **Parallel Model Training**
   - 4 base models train simultaneously instead of sequentially
   - Reduces training time from 50 min â†’ 12 min

4. **Smart Stage Skipping**
   - DVC automatically skips unchanged stages
   - Only retrain models when code/data changes

---

## Live Demo

| Service | URL | Description |
|---------|-----|-------------|
| **FastAPI** | ðŸš€ [Coming Soon] | REST API for predictions |
| **MLflow** | ðŸ“Š [Coming Soon] | Experiment tracking UI |
| **Grafana** | ðŸ“ˆ [Coming Soon] | Monitoring dashboard |

---

## Local Development

### Prerequisites
- Python 3.11+
- Docker & Docker Compose
- Google Cloud account (for DVC remote)
- DVC installed

### Quick Start

```bash
# Clone repository
git clone https://github.com/In-mil/time_series_project.git
cd time_series_project

# Install dependencies
pip install -r requirements.txt

# Pull models and data from DVC
dvc pull -r gcsremote

# Start services with Docker Compose
docker-compose -f docker-compose.monitoring.yml up -d
```

### Services will be available at:
- FastAPI: http://localhost:8000
- MLflow: http://localhost:5001
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000

---

## Collaboration

### For Teammates

1. **Get Repository Access**
   - Contact repository owner for collaborator access

2. **Setup GCP Credentials**
   ```bash
   # You'll need a service account key for DVC
   export GOOGLE_APPLICATION_CREDENTIALS=path/to/your/key.json
   ```

3. **Configure DVC Remote**
   ```bash
   dvc remote modify gcsremote credentialpath $GOOGLE_APPLICATION_CREDENTIALS
   ```

4. **Pull Latest Models**
   ```bash
   dvc pull -r gcsremote
   ```

---
