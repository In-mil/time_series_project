groups:
  - name: model_performance
    interval: 30s
    rules:
      # High prediction latency (95th percentile > 2 seconds)
      - alert: HighPredictionLatency
        expr: histogram_quantile(0.95, rate(prediction_latency_seconds_bucket[5m])) > 2.0
        for: 5m
        labels:
          severity: warning
          service: time-series-api
        annotations:
          summary: "High prediction latency detected"
          description: "95th percentile prediction latency is {{ $value }}s (threshold: 2s). This may indicate model loading issues or resource constraints."

      # Critical latency (99th percentile > 5 seconds)
      - alert: CriticalPredictionLatency
        expr: histogram_quantile(0.99, rate(prediction_latency_seconds_bucket[5m])) > 5.0
        for: 2m
        labels:
          severity: critical
          service: time-series-api
        annotations:
          summary: "CRITICAL: Very high prediction latency"
          description: "99th percentile latency is {{ $value }}s. Immediate action required!"

      # High error rate (>5% of predictions failing)
      - alert: HighPredictionErrorRate
        expr: rate(input_validation_errors_total[5m]) / rate(predictions_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          service: time-series-api
        annotations:
          summary: "High prediction error rate"
          description: "{{ $value | humanizePercentage }} of predictions are failing validation. Check input data quality."

      # Critical error rate (>20%)
      - alert: CriticalPredictionErrorRate
        expr: rate(input_validation_errors_total[5m]) / rate(predictions_total[5m]) > 0.20
        for: 2m
        labels:
          severity: critical
          service: time-series-api
        annotations:
          summary: "CRITICAL: Very high error rate"
          description: "{{ $value | humanizePercentage }} of predictions failing. Service may be degraded!"

      # No predictions in last 10 minutes (service might be down)
      - alert: NoPredictions
        expr: rate(predictions_total[10m]) == 0
        for: 10m
        labels:
          severity: critical
          service: time-series-api
        annotations:
          summary: "No predictions received"
          description: "No predictions in the last 10 minutes. API might be down or not receiving traffic."

      # Sudden spike in prediction volume (>3x normal)
      - alert: PredictionVolumeSpike
        expr: rate(predictions_total[5m]) > 3 * avg_over_time(rate(predictions_total[5m])[1h:5m])
        for: 5m
        labels:
          severity: warning
          service: time-series-api
        annotations:
          summary: "Unusual prediction volume spike"
          description: "Prediction rate is {{ $value | humanize }} requests/sec, which is >3x the hourly average. Possible bot activity or DDoS."

  - name: infrastructure
    interval: 30s
    rules:
      # API is down
      - alert: APIDown
        expr: up{job="time-series-api"} == 0
        for: 2m
        labels:
          severity: critical
          service: time-series-api
        annotations:
          summary: "API is DOWN"
          description: "Time Series API has been down for more than 2 minutes. Check Cloud Run logs."

      # High memory usage (>90%)
      - alert: HighMemoryUsage
        expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.90
        for: 5m
        labels:
          severity: warning
          service: time-series-api
        annotations:
          summary: "High memory usage"
          description: "Memory usage is at {{ $value | humanizePercentage }}. Consider increasing Cloud Run memory allocation."

      # Container restarts
      - alert: ContainerRestarting
        expr: rate(container_restarts_total[5m]) > 0
        for: 1m
        labels:
          severity: warning
          service: time-series-api
        annotations:
          summary: "Container is restarting"
          description: "Container has restarted {{ $value }} times in the last 5 minutes. Check logs for errors."

  - name: model_health
    interval: 1m
    rules:
      # Model predictions are stuck (all models returning same value)
      - alert: ModelPredictionsStuck
        expr: stddev_over_time(last_prediction_value{model="ensemble"}[10m]) < 0.01
        for: 10m
        labels:
          severity: critical
          service: time-series-api
        annotations:
          summary: "Model predictions appear stuck"
          description: "Ensemble model has returned nearly identical predictions for 10 minutes (stddev={{ $value }}). Model may be broken."

      # Individual model consistently different from ensemble
      - alert: ModelDivergence
        expr: abs(last_prediction_value{model="ann"} - last_prediction_value{model="ensemble"}) > 5.0
        for: 15m
        labels:
          severity: warning
          service: time-series-api
        annotations:
          summary: "ANN model diverging from ensemble"
          description: "ANN predictions differ from ensemble by {{ $value }}. Possible model degradation."

      # Too few predictions to calculate metrics
      - alert: InsufficientPredictionData
        expr: increase(predictions_total[1h]) < 10
        for: 1h
        labels:
          severity: info
          service: time-series-api
        annotations:
          summary: "Low prediction volume"
          description: "Only {{ $value }} predictions in the last hour. Monitoring data may be insufficient."

  - name: data_quality
    interval: 1m
    rules:
      # High rate of NaN/Inf in inputs
      - alert: HighInvalidInputRate
        expr: rate(input_validation_errors_total[5m]) > 1.0
        for: 5m
        labels:
          severity: warning
          service: time-series-api
        annotations:
          summary: "High rate of invalid inputs"
          description: "{{ $value }} invalid inputs per second. Check data pipeline quality."

      # Database connection issues
      - alert: DatabaseConnectionIssues
        expr: rate(database_errors_total[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
          service: time-series-api
        annotations:
          summary: "Database connection problems"
          description: "{{ $value }} database errors per second. Prediction logging may be failing."

  # ===========================
  # Drift Detection Alerts
  # ===========================
  - name: drift_detection
    interval: 5m
    rules:
      # Dataset drift detected
      - alert: DatasetDriftDetected
        expr: model_drift_score{drift_type="dataset"} > 0.3
        for: 10m
        labels:
          severity: warning
          service: time-series-api
          category: drift
        annotations:
          summary: "Data drift detected in production"
          description: "Dataset drift score is {{ $value | humanize }}. Input data distribution has changed significantly. Consider retraining the model."

      # Critical dataset drift
      - alert: CriticalDatasetDrift
        expr: model_drift_score{drift_type="dataset"} > 0.5
        for: 5m
        labels:
          severity: critical
          service: time-series-api
          category: drift
        annotations:
          summary: "CRITICAL: Severe data drift detected"
          description: "Dataset drift score is {{ $value | humanize }}. Model may produce unreliable predictions. Immediate retraining recommended."

      # Prediction drift
      - alert: PredictionDriftWarning
        expr: prediction_drift_score > 0.7
        for: 30m
        labels:
          severity: warning
          service: time-series-api
          category: drift
        annotations:
          summary: "Prediction distribution drift detected"
          description: "Prediction drift score is {{ $value | humanize }}. Model outputs show unusual variance."

      # Feature drift (per-feature monitoring)
      - alert: HighFeatureDrift
        expr: feature_drift_score > 0.5
        for: 15m
        labels:
          severity: info
          service: time-series-api
          category: drift
        annotations:
          summary: "Individual feature drift detected"
          description: "Feature {{ $labels.feature_name }} shows drift score of {{ $value | humanize }}."
