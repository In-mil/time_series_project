name: DVC Training & Evaluation Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install "dvc[gs]" tensorflow==2.15.0 mlflow scikit-learn pandas numpy matplotlib seaborn

      - name: Configure Google Cloud and DVC
        env:
          GCP_CREDENTIALS: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
        run: |
          echo "$GCP_CREDENTIALS" > gcp_creds.json
          gcloud auth activate-service-account --key-file=gcp_creds.json
          dvc remote modify gcsremote credentialpath gcp_creds.json

      - name: Pull dataset from GCS (force overwrite)
        run: |
          echo "Pulling dataset from GCS..."
          dvc pull -r gcsremote --force -v
          echo "Verify dataset exists:"
          ls -lh data/final_data/ || true
          test -f data/final_data/20251115_dataset_crp.csv || (echo "Dataset missing!"; exit 1)

      - name: Run full DVC pipeline
        run: |
          echo "Running DVC pipeline..."
          dvc repro evaluate_models -v

      - name: Push updated artifacts and metrics to GCS
        run: |
          echo "Committing and pushing DVC outputs..."
          dvc commit evaluate_models || true
          dvc push -r gcsremote -v

      - name: Upload evaluation report as artifact
        uses: actions/upload-artifact@v4
        with:
          name: model-evaluation-report
          path: reports/metrics.json